{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3083029,"sourceType":"datasetVersion","datasetId":1885267}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport PIL \nfrom PIL import Image\n\nimport torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-21T05:28:07.635397Z","iopub.execute_input":"2024-08-21T05:28:07.635765Z","iopub.status.idle":"2024-08-21T05:28:07.641318Z","shell.execute_reply.started":"2024-08-21T05:28:07.635736Z","shell.execute_reply":"2024-08-21T05:28:07.639889Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"target_path = \"/kaggle/input/d/julinmaloof/the-oxfordiiit-pet-dataset/annotations/trimaps\" \ninput_path = \"/kaggle/input/d/julinmaloof/the-oxfordiiit-pet-dataset/images\"\n\n\ntarget_annots = sorted([\n    os.path.join(target_path, file) for file in os.listdir(target_path) \n    if file.endswith(\".png\") and not file.startswith(\".\")\n])\n\ninput_imgs = sorted([\n    os.path.join(input_path, file) for file in os.listdir(input_path) \n    if file.endswith('.jpg') and not file.startswith('.')\n])\n\nprint(len(target_annots)) \nprint(len(input_imgs)) \n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:28:07.644176Z","iopub.execute_input":"2024-08-21T05:28:07.644617Z","iopub.status.idle":"2024-08-21T05:28:08.620740Z","shell.execute_reply.started":"2024-08-21T05:28:07.644585Z","shell.execute_reply":"2024-08-21T05:28:08.619606Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"7390\n7390\n","output_type":"stream"}]},{"cell_type":"code","source":"\ntransform = transforms.Compose([\n    transforms.Resize((160,160)),\n    transforms.ToTensor()\n])\n\n\ndef get_prepared_data(img_paths, annot_paths):\n    imgs = [] \n    annots = [] \n    for i, (img_path, annot_path ) in enumerate(zip(img_paths, annot_paths)):\n        img = Image.open(img_path) \n        img = transform(img) \n        \n        if img.shape[0] != 3:\n            continue \n        \n        annot = Image.open(annot_path) \n        annot = transform(annot) \n        \n        if annot.shape[0] != 1:\n            continue \n            \n        imgs.append(img) \n        annots.append(annot) \n        \n    return torch.stack(imgs, dim=0), torch.stack(annots, dim=0)\n        \n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:28:08.622582Z","iopub.execute_input":"2024-08-21T05:28:08.623574Z","iopub.status.idle":"2024-08-21T05:28:08.630971Z","shell.execute_reply.started":"2024-08-21T05:28:08.623511Z","shell.execute_reply":"2024-08-21T05:28:08.630110Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_size = int(0.95 * len(input_imgs))\ntrain_imgs_paths = input_imgs[:train_size] \ntrain_targets_paths = target_annots[:train_size] \n\ntrain_imgs, train_targets = get_prepared_data(train_imgs_paths, train_targets_paths)\n\ntest_imgs_path = input_imgs[train_size:]\ntest_targets_path = target_annots[train_size:] \n\ntest_imgs, test_targets = get_prepared_data(test_imgs_path, test_targets_path)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:28:08.632070Z","iopub.execute_input":"2024-08-21T05:28:08.632347Z","iopub.status.idle":"2024-08-21T05:30:51.187123Z","shell.execute_reply.started":"2024-08-21T05:28:08.632324Z","shell.execute_reply":"2024-08-21T05:30:51.186121Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, imgs, annots):\n        self.imgs = imgs\n        self.annots = annots \n        \n    def __len__(self):\n        return len(self.imgs) \n    \n    def __getitem__(self, index):\n        return self.imgs[index], self.annots[index] \n    \n    \n\ntrain_ds = CustomDataset(train_imgs, train_targets) \ntest_ds = CustomDataset(test_imgs, test_targets) \n\ntrain_dl = DataLoader(train_ds, batch_size=32, shuffle=True) \ntest_dl = DataLoader(test_ds, batch_size=32) \n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.189851Z","iopub.execute_input":"2024-08-21T05:30:51.190275Z","iopub.status.idle":"2024-08-21T05:30:51.361729Z","shell.execute_reply.started":"2024-08-21T05:30:51.190244Z","shell.execute_reply":"2024-08-21T05:30:51.360954Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(len(train_dl.dataset))\nprint(len(test_dl.dataset))","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.362848Z","iopub.execute_input":"2024-08-21T05:30:51.363164Z","iopub.status.idle":"2024-08-21T05:30:51.367674Z","shell.execute_reply.started":"2024-08-21T05:30:51.363140Z","shell.execute_reply":"2024-08-21T05:30:51.366746Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"7008\n370\n","output_type":"stream"}]},{"cell_type":"code","source":"annot = Image.open(train_targets_paths[0])\ntrns = transforms.Compose([\n    transforms.ToTensor()\n])\nannot = torch.round(trns(annot) /0.0039)\n\ntorch.unique(annot)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.368775Z","iopub.execute_input":"2024-08-21T05:30:51.369058Z","iopub.status.idle":"2024-08-21T05:30:51.420904Z","shell.execute_reply.started":"2024-08-21T05:30:51.369035Z","shell.execute_reply":"2024-08-21T05:30:51.420006Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"tensor([1., 2., 3.])"},"metadata":{}}]},{"cell_type":"code","source":"class DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DownBlock, self).__init__()  \n        self.relu_1 = nn.ReLU() \n        self.conv_1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding=1) \n        self.bn_1 = nn.BatchNorm2d(out_channels) \n        \n        self.relu_2 = nn.ReLU() \n        self.conv_2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding=1) \n        self.bn_2 = nn.BatchNorm2d(out_channels) \n        \n        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) \n        \n        self.resid = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, padding=0) \n        \n    def forward(self, x, prev_block):\n        x = self.relu_1(x) \n        x = self.conv_1(x) \n        x = self.bn_1(x) \n        x = self.relu_2(x) \n        x = self.conv_2(x) \n        x = self.bn_2(x) \n        x = self.pool(x)\n        \n        resid = self.resid(prev_block) \n        x = torch.add(x, resid) \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.421933Z","iopub.execute_input":"2024-08-21T05:30:51.422179Z","iopub.status.idle":"2024-08-21T05:30:51.431520Z","shell.execute_reply.started":"2024-08-21T05:30:51.422158Z","shell.execute_reply":"2024-08-21T05:30:51.430603Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"x = torch.randn(1,3,160,160) \nprev_block = x \ndown = DownBlock(3, 64) \ny = down(x ,prev_block) \nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.432685Z","iopub.execute_input":"2024-08-21T05:30:51.433003Z","iopub.status.idle":"2024-08-21T05:30:51.561037Z","shell.execute_reply.started":"2024-08-21T05:30:51.432980Z","shell.execute_reply":"2024-08-21T05:30:51.560239Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"torch.Size([1, 64, 80, 80])\n","output_type":"stream"}]},{"cell_type":"code","source":"class UpBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(UpBlock, self).__init__() \n        self.relu_1 = nn.ReLU() \n        self.conv_1 = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1) \n        self.bn_1 = nn.BatchNorm2d(out_channels) \n        \n        self.relu_2 = nn.ReLU() \n        self.conv_2 = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=3, padding=1) \n        self.bn_2 = nn.BatchNorm2d(out_channels)\n        \n        self.up_sample_1 = nn.Upsample(scale_factor=2) \n        self.up_sample_2 = nn.Upsample(scale_factor=2) \n        \n        self.conv_3 = nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=0) \n        \n    def forward(self, x, prev_block):\n        x = self.relu_1(x) \n        x = self.conv_1(x) \n        x = self.bn_1(x) \n        \n        x = self.relu_2(x) \n        x = self.conv_2(x) \n        x = self.bn_2(x) \n        \n        x = self.up_sample_1(x) \n       \n        \n        resid = self.up_sample_2(prev_block) \n        resid = self.conv_3(resid) \n   \n        x = torch.add(x, resid) \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.562118Z","iopub.execute_input":"2024-08-21T05:30:51.562403Z","iopub.status.idle":"2024-08-21T05:30:51.572034Z","shell.execute_reply.started":"2024-08-21T05:30:51.562378Z","shell.execute_reply":"2024-08-21T05:30:51.571096Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"x = torch.randn(1,3,160,160) \nprev_block = x \n\nin_channels = 3\nout_channels = 32 \nupblock = UpBlock(in_channels, out_channels) \n\nz = upblock(x, prev_block) \nprint(z.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.575789Z","iopub.execute_input":"2024-08-21T05:30:51.576158Z","iopub.status.idle":"2024-08-21T05:30:51.658492Z","shell.execute_reply.started":"2024-08-21T05:30:51.576125Z","shell.execute_reply":"2024-08-21T05:30:51.657548Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"torch.Size([1, 32, 320, 320])\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, num_classes=3):\n        super(CustomModel, self).__init__() \n        self.conv = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=2, padding=1) \n        self.bn = nn.BatchNorm2d(32) \n        self.relu = nn.ReLU() \n        \n        \n        self.outputs = nn.Conv2d(32, num_classes, kernel_size=3,padding=1) \n        self.softmax = nn.Softmax(dim=1) \n        \n    def forward(self, x):\n        x = self.conv(x) \n        x = self.bn(x) \n        x = self.relu(x) \n\n        prev_block = x\n        in_channels = 32\n        \n        for filters in [64,128,256]:\n            x = DownBlock(in_channels, filters)(x, prev_block) \n            prev_block = x \n            in_channels = filters \n            \n        for filters in [256,128,64,32]:\n            x = UpBlock(in_channels, filters)(x, prev_block) \n            prev_block = x \n            in_channels = filters \n            \n        outputs = self.outputs(x)\n        outputs = self.softmax(outputs)\n        return outputs\n      \n\nx = torch.randn(1,3,160,160) \ny = CustomModel()(x) \nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.659727Z","iopub.execute_input":"2024-08-21T05:30:51.660009Z","iopub.status.idle":"2024-08-21T05:30:51.783859Z","shell.execute_reply.started":"2024-08-21T05:30:51.659986Z","shell.execute_reply":"2024-08-21T05:30:51.782964Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 160, 160])\n","output_type":"stream"}]},{"cell_type":"code","source":"model = CustomModel()  \n\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\") \nmodel = model.to(device)\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:43:25.015580Z","iopub.execute_input":"2024-08-21T05:43:25.016200Z","iopub.status.idle":"2024-08-21T05:43:25.023451Z","shell.execute_reply.started":"2024-08-21T05:43:25.016169Z","shell.execute_reply":"2024-08-21T05:43:25.022568Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"optim = torch.optim.Adam(params = model.parameters(), lr=1e-3)\nloss_fn = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:30:51.793478Z","iopub.execute_input":"2024-08-21T05:30:51.793784Z","iopub.status.idle":"2024-08-21T05:30:51.799866Z","shell.execute_reply.started":"2024-08-21T05:30:51.793762Z","shell.execute_reply":"2024-08-21T05:30:51.799099Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\ndef train_model(model, data, optim, loss_fn, epochs):\n    size = len(data.dataset) \n    all_losses = [] \n    all_accuracies = [] \n    \n    model.train() \n    for epoch in range(epochs):\n        losses = [] \n        accuracies = [] \n        print(f'\\n\\nEpoch : {epoch+1} ------------------------------------')\n        for batch, (X,y) in enumerate(data):\n            X = X.to(device) \n            y = torch.round(y /0.0039)\n            y = y.to(torch.long) -1 \n            y = y.view(-1, 160,160)\n            y = y.to(device)\n            preds = model(X) \n            loss = loss_fn(preds, y) \n            loss.backward() \n            \n            optim.step() \n            optim.zero_grad()  \n            \n            loss = loss.item() \n            losses.append(loss) \n            points = y.shape[0]*y.shape[1]*y.shape[2] \n            accu = (preds.argmax(1) == y).type(torch.float).sum().item() / points\n            accuracies.append(accu)  \n            current = batch * batch_size + len(y) \n            if batch % 50 ==0:\n                print(f\"Loss : {loss:.3f} | Accuracy : {accu:.3f} Current : [{current :>3d}/{size}]\")\n            \n        all_losses.append(losses) \n        all_accuracies.append(accuracies) \n        \n    \n    return all_losses, all_accuracies\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:41:26.964408Z","iopub.execute_input":"2024-08-21T05:41:26.964790Z","iopub.status.idle":"2024-08-21T05:41:26.975183Z","shell.execute_reply.started":"2024-08-21T05:41:26.964757Z","shell.execute_reply":"2024-08-21T05:41:26.974301Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"losses, accuracies = train_model(model, train_dl, optim, loss_fn, 1)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:41:35.998319Z","iopub.execute_input":"2024-08-21T05:41:35.998948Z","iopub.status.idle":"2024-08-21T05:41:36.241441Z","shell.execute_reply.started":"2024-08-21T05:41:35.998917Z","shell.execute_reply":"2024-08-21T05:41:36.240210Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"\n\nEpoch : 1 ------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses, accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[26], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, data, optim, loss_fn, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m160\u001b[39m,\u001b[38;5;241m160\u001b[39m)\n\u001b[1;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 19\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, y) \n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mCustomModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filters \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m256\u001b[39m]:\n\u001b[0;32m---> 21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mDownBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_block\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     22\u001b[0m     prev_block \u001b[38;5;241m=\u001b[39m x \n\u001b[1;32m     23\u001b[0m     in_channels \u001b[38;5;241m=\u001b[39m filters \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36mDownBlock.forward\u001b[0;34m(self, x, prev_block)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, prev_block):\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu_1(x) \n\u001b[0;32m---> 18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn_1(x) \n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu_2(x) \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"],"ename":"RuntimeError","evalue":"Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same","output_type":"error"}]},{"cell_type":"code","source":"x = 2.5234315\nprint(f\"{x:.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:32:57.853098Z","iopub.status.idle":"2024-08-21T05:32:57.853754Z","shell.execute_reply.started":"2024-08-21T05:32:57.853491Z","shell.execute_reply":"2024-08-21T05:32:57.853511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logits = torch.randn(32,3,160,160) \ntarget = torch.randint(0,3,(32,1,160,160), dtype=torch.long) \n\ntarget = target.view(-1,160,160)\nloss = loss_fn(logits, target) \n\nprint(logits.shape) \nprint(target.shape)\nprint(loss)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T05:32:57.855039Z","iopub.status.idle":"2024-08-21T05:32:57.855582Z","shell.execute_reply.started":"2024-08-21T05:32:57.855321Z","shell.execute_reply":"2024-08-21T05:32:57.855343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}